---
`---
title: "AML"
format: html
editor: visual
---

```{r}
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
if (!requireNamespace("doParallel", quietly = TRUE))
    install.packages("doParallel")
if (!requireNamespace("rafalib", quietly = TRUE))
    install.packages("rafalib")
if (!requireNamespace("DESeq2", quietly = TRUE))
  BiocManager::install("DESeq2")
if (!requireNamespace("GSVA", quietly = TRUE))
  BiocManager::install("GSVA", update = TRUE, ask = FALSE)
if (!requireNamespace("edgeR", quietly = TRUE))
  BiocManager::install("edgeR", update = TRUE, ask = FALSE)
if (!requireNamespace("FactoMineR", quietly = TRUE)) 
  install.packages("FactoMineR")
library(tidyverse)
library(readr)
library(biomaRt)
library(data.table)
library(doParallel)
library(future)
library(furrr)
library(survival)
library(DESeq2)
library(GSVA)
library(ggplot2)
library(dplyr)
library(edgeR)
library(purrr)
library(ggrepel)
library(FactoMineR)
library(sva)
library(rafalib)
```

```{r}
metadata <- read_tsv("TARGET_AML_Clinical.tsv")
head(metadata)
```

## Counts data pre-processing

Since we have different tsv files for every sample, we need to load them all, pre-process them and merge them.

We can create two files:

1.  One with gene names as row names and samples as column names. Here, because multiple gene ids may map to the same gene name we must either sum those (approach A), keep the most expressed isoform (approach B) or another handling.

2.  The same but with gene ids as row names, samples as column names plus another column with the gene names. Could be useful if we try CAR-T cell target evaluation for isoforms (maybe this is too much).

```{r}
# Creates the data frame "merged_counts"
# Doesn't include gene_id 
# Sum the isoforms approach

# Step 0: Define the output file path for merged_counts
output_file <- "merged_counts.tsv"

# Step 1: List all TSV files in the counts directory (this part is now global)
counts_files <- list.files(path = "counts/", pattern = "\\.tsv$", full.names = TRUE)

# Step 2: Check if the file already exists
if (file.exists(output_file)) {
  # If the file exists, load it
  merged_counts <- read.delim(output_file, sep = "\t", header = TRUE, row.names = 1)
  print("Merged counts loaded from file.")
} else {
  # If the file does not exist, run the processing code to create it

  # Step 3: Set up parallel plan
  plan(multisession, workers = parallel::detectCores() - 1)

  # Step 4: Define the processing function for each file
  process_file <- function(file) {
    # Load the file into a dataframe
    df <- read.delim(file, sep = "\t", header = TRUE)

    # Convert to tibble to work smoothly with dplyr functions
    df <- as_tibble(df)

    # Perform preprocessing
    # Drop columns that we do not need
    columns_to_drop <- c("gene_id", "gene_type", "unstranded", "tpm_unstranded", "fpkm_unstranded", "fpkm_uq_unstranded")
    df <- dplyr::select(df, -all_of(columns_to_drop))

    # Drop columns that have all NA values
    df <- dplyr::select(df, where(~ any(!is.na(.))))

    # Sum values from "stranded_first" and "stranded_second"
    df <- df %>%
      mutate(summed_counts = stranded_first + stranded_second) %>%
      dplyr::select(-stranded_first, -stranded_second)  # Drop the original columns

    # Rename the resulting column to the file name
    new_column_name <- gsub(".*/|\\.tsv$", "", file) # Remove path and extension
    df <- dplyr::rename(df, !!new_column_name := summed_counts)

    # Group by gene_name and take the sum for duplicated gene names
    df <- df |>
      group_by(gene_name) |>
      summarise(across(everything(), sum, na.rm = TRUE), .groups = "drop")

    # Round all values to the nearest integer
    df <- df |>
      mutate(across(where(is.numeric), round))

    return(df)
  }

  # Step 5: Apply the function to each file in parallel using furrr::future_map
  counts_dataframe_list <- furrr::future_map(counts_files, process_file)

  # Step 6: Merge all dataframes in the list by "gene_name"
  merged_counts <- purrr::reduce(counts_dataframe_list, full_join, by = "gene_name")

  # Step 7: Make gene_names the row names
  merged_counts <- merged_counts |> column_to_rownames(var = "gene_name")

  # Step 8: Save the merged_counts to a TSV file
  write.table(merged_counts, file = output_file, sep = "\t", quote = FALSE, col.names = NA)
  print("Merged counts computed and saved to file.")
}

# Check the merged dataframe
print(merged_counts)
```

```{r}
# TO BE USED IF WE ANALYZE ISOFORMS
# Creates the data frame "merged_counts_with_ids"
# Includes gene_id

# Step 1: Initialize an empty list to store dataframes
counts_dataframe_list_with_ids <- list()

# Step 2: Loop through each file, read it, process, and store in the list
for (file in counts_files) {
  # Load the file into a dataframe
  df <- read.delim(file, sep = "\t", header = TRUE)

  # Perform preprocessing
  # Drop columns that we do not need (assuming we keep stranded_first, stranded_second, and gene_id)
  columns_to_drop <- c("gene_type", "unstranded", "tpm_unstranded", "fpkm_unstranded", "fpkm_uq_unstranded")
  df <- df[, !(names(df) %in% columns_to_drop)]

  # Drop columns that have all NA values
  df <- df[, colSums(!is.na(df)) > 0]

  # Add `stranded_first` and `stranded_second` and create a new combined column
  df$combined_stranded <- rowSums(df[, c("stranded_first", "stranded_second")], na.rm = TRUE)

  # Drop `stranded_first` and `stranded_second`
  df <- df[, !(names(df) %in% c("stranded_first", "stranded_second"))]

  # Rename the combined column to the file name
  new_column_name <- gsub(".*/|\\.tsv$", "", file)
  colnames(df)[colnames(df) == "combined_stranded"] <- new_column_name

  # Store the dataframe in the list
  counts_dataframe_list_with_ids[[file]] <- df
}

# Step 3: Merge all dataframes in the list by both "gene_name" and "gene_id"
merged_counts_with_ids <- purrr::reduce(counts_dataframe_list_with_ids, full_join, by = c("gene_name", "gene_id"))

# Check the merged dataframe
print(merged_counts_with_ids)
```

## Metadata pre-processing

We care about the following variables:

-   Vital status (alive/dead)

-   Overall survival time in days

-   MRD at end of course 1&2 (for stratifying patients)

-   CR status at end of course 1&2 (for stratifying patients)

```{r}
# Keep only the variables we will work with
metadata <- metadata[, c("TARGET USI", "Vital Status", "Overall Survival Time in Days", "MRD at end of course 1", "CR status at end of course 1", "Protocol")]

# Drop rows with NAs
metadata <- na.omit(metadata)

# Keep only rows for the patients we chose
# Extract sample names from the list of filenames
sample_names <- basename(counts_files)
sample_names <- gsub("\\.tsv$", "", sample_names)
# Filter metadata to keep only rows matching the extracted sample names
metadata <- metadata[metadata$`TARGET USI` %in% sample_names, ]

# Standardize the column names to make them easier to work with
names(metadata) <- gsub("[[:space:]]|\\.", "_", names(metadata))

# Rename columns for simplicity
names(metadata)[names(metadata) == "MRD_at_end_of_course_1"] <- "MRD_status"
names(metadata)[names(metadata) == "CR_status_at_end_of_course_1"] <- "CR_status"
names(metadata)[names(metadata) == "Overall_Survival_Time_in_Days"] <- "Survival_Time"

# Convert the values of the CR_status column (it is needed later for DESeq)
metadata$CR_status <- ifelse(metadata$CR_status == "CR", "Yes", "No")
```

## PCA on the data

```{r}
# Prepare the data
# Remove non-numeric columns (gene_id and gene_name)
# Step 1: Extract expression data and transpose
expression_data <- t(as.matrix(merged_counts))

# Step 2: Assign sample IDs as row names
rownames(expression_data) <- colnames(merged_counts)
rownames(expression_data) <- gsub("\\.", "-", rownames(expression_data))

# Step 3: Replace infinite values with NA
expression_data[is.infinite(expression_data)] <- NA

# Step 4: Replace NA with column mean
for (i in seq_len(ncol(expression_data))) {
  expression_data[is.na(expression_data[, i]), i] <- mean(expression_data[, i], na.rm = TRUE)
}

# Step 5: Filter features based on variance
variances <- apply(expression_data, 2, var, na.rm = TRUE)
threshold <- 0.0001  # Adjust as per your dataset
high_variance_features <- variances > threshold
expression_data <- expression_data[, high_variance_features]

# Output remaining features
cat("Remaining features after variance filter:", ncol(expression_data), "\n")

# Step 6: Standardize the data
standardized_data <- scale(expression_data)

# Final checks
cat("Dimension of standardized data:", dim(standardized_data), "\n")

```

```{r}
# Check alignment
all(rownames(expression_data) %in% metadata$TARGET_USI)  # Should return TRUE

```

```{r}
# Perform PCA using prcomp()
# standardized_data should have rows as samples and columns as features
pca_result <- prcomp(standardized_data, scale. = TRUE)

# Extract variance explained by the first two components
explained_variance <- (pca_result$sdev^2) / sum(pca_result$sdev^2) * 100
PC1_variance <- round(explained_variance[1], 2)
PC2_variance <- round(explained_variance[2], 2)

# Create a data frame for PCA results
pca_data <- data.frame(
  Sample = rownames(standardized_data),
  PC1 = pca_result$x[, 1],
  PC2 = pca_result$x[, 2]
)

# Merge PCA results with metadata
pca_data <- left_join(pca_data, metadata, by = c("Sample" = "TARGET_USI"))

# Plot PCA stratified by CR_status
ggplot(pca_data, aes(x = PC1, y = PC2, color = CR_status, label = Sample)) +
  geom_point(size = 4) +
  geom_text(vjust = -0.5, hjust = 0.5, size = 3) +
  ggtitle("PCA Stratified by CR_status (Filtered Data)") +
  xlab(paste0("Principal Component 1 (", PC1_variance, "% variance explained)")) +
  ylab(paste0("Principal Component 2 (", PC2_variance, "% variance explained)")) +
  scale_color_discrete(name = "CR Status") +
  theme_minimal()
```

## SVA

```{r}
# Replace dots with hyphens in rownames of standardized_data
rownames(standardized_data) <- gsub("\\.", "-", rownames(standardized_data))

# Check alignment again
if (!all(rownames(metadata) %in% rownames(standardized_data))) {
  cat("Samples still do not fully align. Missing samples:\n")
  missing_samples <- setdiff(rownames(metadata), rownames(standardized_data))
  print(missing_samples)
} else {
  cat("Sample names are now aligned.\n")
}

```

```{r}
rownames(standardized_data)
```

```{r}
cat("Dimensions of expression_data: ", dim(expression_data), "\n")

```

We have to take account for the batch effects. We don t know If there are any so we are going to use the SVA to account for latent batch effects

## *We have to take account for the batch effects. We don t know If there are any so we are going to use the SVA to account for latent batch effects* \https://biodatascience.github.io/compbio/dist/sva.html\*

```{r}

View(merged_counts_with_ids)
```

```{r}
colnames(merged_counts_with_ids)

```

```{r}
# Ensure gene_name is unique
merged_counts_with_ids$gene_name <- make.unique(as.character(merged_counts_with_ids$gene_name))

# Set row names to the "gene_name" column
rownames(merged_counts_with_ids) <- merged_counts_with_ids$gene_name

# Drop the "gene_id" and "gene_name" columns
merged_counts_with_ids <- merged_counts_with_ids[, !colnames(merged_counts_with_ids) %in% c("gene_id", "gene_name")]

# Check the result
head(merged_counts_with_ids)  # Display the first few rows

```

```{r}
length(colnames(merged_counts_with_ids))
length(rownames(metadata))

```

```{r}
# Check lengths to ensure they match
if (length(colnames(merged_counts_with_ids)) == length(rownames(metadata))) {
  # Replace column names of merged_counts_with_ids with row names of metadata
  colnames(merged_counts_with_ids) <- rownames(metadata)
} else {
  stop("The number of columns in merged_counts_with_ids does not match the number of rows in metadata.")
}

# Verify the alignment
all(colnames(merged_counts_with_ids) == rownames(metadata))

```

```{r}
colnames(merged_counts_with_ids)
rownames(metadata)
```

```{r}
# DESeq is performed ALWAYS with raw counts
dds <- DESeqDataSetFromMatrix(countData = merged_counts, colData = metadata, design = ~ CR_status)

# Pre-filtering: remove rows with low gene counts (keep rows that have at least 10 reads total) - recommended but not mandatory step
keep <- rowSums(counts(dds)) >= 10
dds <- dds[keep, ]

# Run DESeq
dds <- DESeq(dds)
```

```{r}
#We estimate the library size correction and save the normalized counts matrix:

dds <- estimateSizeFactors(dds)
norm.cts <- counts(dds, normalized=TRUE)
```

```{r}
# Ensure 'CR_status' and any other relevant variables are factors
colData(dds)$CR_status <- factor(colData(dds)$CR_status)

# If you have a 'batch' variable, ensure it is a factor as well
# For example:
# colData(dds)$batch <- factor(colData(dds)$batch)

# Extract normalized counts
norm.cts <- counts(dds, normalized=TRUE)

# Filter rows with all zero counts
norm.cts <- norm.cts[rowSums(norm.cts) > 0, ]

# Create design matrices
# Full model includes known biological covariates
mm <- model.matrix(~ CR_status, colData(dds))

# Null model includes only the intercept
mm0 <- model.matrix(~ 1, colData(dds))

# Run SVA to estimate surrogate variables
fit <- svaseq(norm.cts, mod = mm, mod0 = mm0)

# Inspect the result
fit
```

## Based on the SVA we identified 6 surrogated variables

Plot

```{r}
# Set up plotting area
bigpar()

# Convert CR_status to integers for plotting shapes
colData(dds)$CR_status.int <- as.integer(colData(dds)$CR_status)

# Plot the first two surrogate variables (SV1 and SV2)
plot(
  fit$sv[, 1:2],
  col = "black",                    # Single color (no batch variable)
  pch = colData(dds)$CR_status.int, # Shape determined by CR_status
  cex = 2,                          # Point size
  xlab = "SV1",
  ylab = "SV2"
)

# Add a legend for CR_status
legend(
  "topright",
  legend = levels(colData(dds)$CR_status), # Levels of CR_status
  pch = unique(colData(dds)$CR_status.int), # Match shapes
  col = "black",                           # Single color
  cex = 0.8,
  ncol = 2,
  title = "CR_status"
)


```

-   

-   **Separation by `CR_status`:**

    -   The two shapes (`△` for "No" and `○` for "Yes") seem scattered and overlap significantly. There isn't a clear clustering of points based on `CR_status`, which may suggest that the surrogate variables are capturing other hidden variations (not necessarily batch effects).

-   **Batch Effects Likely Absent:**

    -   If batch effects were strongly influencing the data, you would typically see clusters or groupings that align with the batches (if batch variables existed). Since you don't have a `batch` variable and the plot shows no distinct clustering, batch effects are not apparent.

    ## Surrogate Variables by Sample Order Plot:

    ```{r}
    plot(1:nrow(fit$sv), fit$sv[, 1], type = "b", xlab = "Sample Index", ylab = "SV1")

    ```

```{r}
# PCA on surrogate variables
# Calculate variance explained by each PC
explained_variance <- round(100 * pca_sv$sdev^2 / sum(pca_sv$sdev^2), 2)

# Create axis labels with explained variance
x_label <- paste0("PC1 (", explained_variance[1], "% Variance)")
y_label <- paste0("PC2 (", explained_variance[2], "% Variance)")

# Visualize PCA with explained variance in axis labels
ggplot(pca_data, aes(x = PC1, y = PC2, color = CR_status)) +
  geom_point(size = 3) +
  labs(title = "PCA of Surrogate Variables", x = x_label, y = y_label) +
  theme_minimal()



```

-   **Fluctuations Without Clear Clusters:**

    -   The surrogate variable (SV1) fluctuates across sample indices but doesn't show systematic clustering or a clear trend that could be indicative of batch effects.

-   **No Apparent Batch-Like Patterns:**

    -   If batch effects were present, you might expect:

        -   Distinct blocks or clusters of samples where SV1 values differ significantly.

        -   Systematic increases or decreases across contiguous sample indices (e.g., sequencing batches processed sequentially).

## Examine Variance Explained by Surrogate Variables

```{r}
summary(prcomp(fit$sv))
```

```{r}
# Design matrix with CR_status and surrogate variables
design <- cbind(mm, fit$sv)

```

Fit limma to the SVA data

```{r}
library(limma)
fit_limma <- lmFit(norm.cts, design)

```

```{r}
fit_limma <- eBayes(fit_limma)

# Extract top differentially expressed genes
topTable(fit_limma, coef = "CR_statusYes", adjust.method = "BH")

```

```{r}
# Assuming your table is stored in a data frame called 'results'
# Add a column for significance based on adjusted p-value and logFC thresholds
results$Significant <- ifelse(results$adj.P.Val < 0.05 & abs(results$logFC) > 1, "Yes", "No")

# Load ggplot2 for visualization
library(ggplot2)

# Create the volcano plot
ggplot(results, aes(x = logFC, y = -log10(P.Value), color = Significant)) +
  geom_point(alpha = 0.6, size = 2) +  # Scatter plot with transparency
  scale_color_manual(values = c("No" = "gray", "Yes" = "red")) +  # Color for significant points
  labs(
    title = "Volcano Plot",
    x = "Log2 Fold Change (logFC)",
    y = "-log10 P-Value"
  ) +
  theme_minimal() +
  theme(legend.position = "top")


```

```{r}
# Filter significant genes based on thresholds
significant_genes <- results[results$adj.P.Val < 0.05 & abs(results$logFC) > 1, ]

# Extract the gene names (assuming the gene names are stored in a column called "Gene")
significant_gene_names <- rownames(significant_genes)  # Or use `results$Gene` if there's a "Gene" column

# Print the significant gene names
print(significant_gene_names)

# If you want to save the gene names to a file:
write.table(significant_gene_names, file = "significant_genes.txt", quote = FALSE, row.names = FALSE, col.names = FALSE)

```

Limma assuming every sample is a batch.... I did nt like it

```{r}
expr_matrix <- merged_counts  # Transpose to genes × samples
rownames(expr_matrix)
# Replace 'CR_status' with the actual column name in metadata
metadata$batch <- seq_len(nrow(metadata))  # Assign unique batch IDs
metadata
```

colnames(expr_matrix)

```{r}
# Replace periods (.) with hyphens (-) in column names of expr_matrix
colnames(expr_matrix) <- gsub("\\.", "-", colnames(expr_matrix))

# Check the result
head(colnames(expr_matrix))
# Reorder metadata to match the columns of expr_matrix
metadata <- metadata[match(colnames(expr_matrix), metadata$TARGET_USI), ]

# Continue with batch correction, scaling, PCA, etc.

```

```{r}
# Load required library
library(limma)

# Ensure batch is a factor
metadata$batch <- as.factor(metadata$batch)

# Optional: Define biological covariates to preserve (e.g., CR_status)

# Perform batch correction
limma_corrected <- removeBatchEffect(
  expr_matrix,
  batch = metadata$batch
)


# View corrected data
head(limma_corrected)

```

```{r}
# Load necessary library
library(caret) # for nearZeroVar function

# Identify near-zero variance columns
nzv <- nearZeroVar(filtered_matrix, saveMetrics = TRUE)

# Retain only columns with non-zero variance
filtered_matrix <- filtered_matrix[, !nzv$nzv]

# Check the dimensions of the filtered matrix
cat("Filtered matrix dimensions after removing near-zero variance columns:", dim(filtered_matrix), "\n")

# Scale the filtered matrix explicitly
scaled_matrix <- scale(filtered_matrix)

# Check dimensions of the scaled matrix
cat("Scaled matrix dimensions:", dim(scaled_matrix), "\n")

# Perform PCA
if (nrow(scaled_matrix) > ncol(scaled_matrix)) {
  scaled_matrix <- t(scaled_matrix)
}

pca_result <- prcomp(scaled_matrix, center = TRUE, scale. = FALSE) # No need to scale again

# View PCA summary
summary(pca_result)

# Extract PCA scores for visualization
pca_scores <- as.data.frame(pca_result$x)

# Plot the first two principal components
# Calculate variance explained by each PC
explained_variance <- round(100 * pca_result$sdev^2 / sum(pca_result$sdev^2), 2)

# Create labels with variance explained
x_label <- paste0("PC1 (", explained_variance[1], "% Variance)")
y_label <- paste0("PC2 (", explained_variance[2], "% Variance)")

# Plot the first two principal components
library(ggplot2)
ggplot(pca_scores, aes(x = PC1, y = PC2, color = metadata$CR_status)) +
  geom_point(size = 3) +
  labs(
    title = "PCA Plot",
    x = x_label,
    y = y_label
  ) +
  theme_minimal()



```

```{r}
# Identify columns where all rows are zero or constant
constant_columns <- apply(merged_data[, -which(names(merged_data) %in% c("sample_id", "CR_status"))], 2, function(x) sd(x) == 0)

# Remove constant columns
merged_data_cleaned <- merged_data[, !constant_columns]

# Scale the cleaned data (excluding 'sample_id' and 'CR_status' columns)
merged_data_scaled <- scale(merged_data_cleaned[, -which(names(merged_data_cleaned) %in% c("sample_id", "CR_status"))])

# Perform PCA
pca_result <- prcomp(merged_data_scaled, center = TRUE, scale. = TRUE)

# Summary of PCA to understand variance explained
summary(pca_result)

# Create a PCA dataframe with the results
pca_data <- data.frame(pca_result$x)  # Extract PCA scores
pca_data$CR_status <- merged_data$CR_status  # Add CR_status for coloring

# Plotting the PCA
library(ggplot2)
ggplot(pca_data, aes(x = PC1, y = PC2, color = CR_status)) +
  geom_point(size = 3) +
  labs(title = "PCA of Batch Corrected Data with CR Status",
       x = paste("PC1 - ", round(100 * summary(pca_result)$importance[2, 1]), "% variance"),
       y = paste("PC2 - ", round(100 * summary(pca_result)$importance[2, 2]), "% variance")) +
  theme_minimal() +
  scale_color_manual(values = c("red", "blue"))  # Customize color palette (adjust as needed)

```

## Survival analysis

```{r}
# We want to stratify patients based on "MRD" or "CR", so we first need to convert them to 'factor'
metadata$MRD_status <- factor(metadata$MRD_status, levels = c("No", "Yes"))
metadata$CR_status <- factor(metadata$CR_status, levels = c("No", "Yes"))

# We also need to convert "Vital status" to a boolean (0 for alive, 1 for dead)
metadata$Vital_Status <- ifelse(metadata$Vital_Status == "Dead", 1, 0)

# Create the survival object
sd <- survdiff(Surv(Survival_Time, Vital_Status) ~ CR_status, data = metadata)
sd

# Save the p-value
p_value <- 1 - pchisq(sd$chisq, length(sd$n) - 1)

# Create the Kaplan-Meier object and plot it
km <- survfit(Surv(Survival_Time, Vital_Status) ~ CR_status, data = metadata)
plot(km, xlim = c(0, 1200), xlab = "Time in Days", ylab = "Survival Probability",main = "Kaplan-Meier Plot")
text(x = 800, y = 0.2, labels = paste("p-value =", round(p_value, 4)), col = "red", cex = 1.2)
```

*We don't find a **p-value** \< 0.05, which means the difference is not significant (p-value = 0.6 for MRD and 0.09 for CR).*

## DESeq

*We will perform differential gene expression analysis in order to find genes differentially expressed between responders and non-responders.*

```{r}
# Create the DESeq object and run DESeq
# DESeq is performed ALWAYS with raw counts
dds <- DESeqDataSetFromMatrix(countData = merged_counts, colData = metadata, design = ~ CR_status)

# Pre-filtering: remove rows with low gene counts (keep rows that have at least 10 reads total) - recommended but not mandatory step
keep <- rowSums(counts(dds)) >= 10
dds <- dds[keep, ]

# Run DESeq
dds <- DESeq(dds)

# Store the results and display a table of the number of significantly differentially expresssed genes
res <- as.data.frame(results(dds))
res <- res %>% 
  dplyr::filter(log2FoldChange > -10)
cat("Significantly differentially expressed genes between responders and non-responders.\n\nThis number doesn't add up to the total number of genes in merged_counts because there are NA values in p-adj for some genes.\n")
print(table(res$padj < 0.05))

# Filter the significant genes and extract their names
significant_genes <- res[!is.na(res$padj) & res$padj < 0.05, ]
significant_gene_names <- rownames(significant_genes)
head(sort(significant_gene_names), 100)
```

*We found a satisfactory amount of differentially expressed genes. We will try to stratify patients on those. We will find the median expression and see if their expression is higher or lower. Because in this way we **COMPARE** samples, we need to use TPM values (or RPKM) and not raw counts, since we need to normalize for **SEQUENCING DEPTH**.*

## Volcano plot

```{r}
# Add a significance column for plotting
res$significance <- "Not Significant"
res$significance[res$padj < 0.05 & res$log2FoldChange > 0] <- "Upregulated"
res$significance[res$padj < 0.05 & res$log2FoldChange < 0] <- "Downregulated"

# Volcano plot
volcano_plot <- ggplot(res, aes(x = log2FoldChange, y = -log10(padj), color = significance)) +
  geom_point(alpha = 0.8, size = 1.5) +  # Points for genes
  scale_color_manual(values = c("Not Significant" = "grey", 
                                "Upregulated" = "red", 
                                "Downregulated" = "blue")) +
  theme_minimal() +
  labs(title = "",
       x = "Log2 Fold Change",
       y = "-Log10 Adjusted P-value",
       color = "Significance") +
  theme(legend.position = "top")

# Step 1: Subset for upregulated and downregulated genes
upregulated_genes <- res[res$significance == "Upregulated", ]    # Select genes labeled as Upregulated
downregulated_genes <- res[res$significance == "Downregulated", ]  # Select genes labeled as Downregulated

# Step 2: Sort by significance (adjusted p-value) and select the top 10 from each
top_upregulated_genes <- upregulated_genes[order(upregulated_genes$padj), ][1:10, ]
top_downregulated_genes <- downregulated_genes[order(downregulated_genes$padj), ][1:10, ]

# Step 3: Combine the selected genes for labeling
top_genes <- rbind(top_upregulated_genes, top_downregulated_genes)

# Add labels to the plot for the selected top genes
volcano_plot <- volcano_plot +
  geom_text_repel(data = top_genes, aes(label = rownames(top_genes)), size = 3, vjust = -0.5, max.overlaps = Inf)

# Print the volcano plot
print(volcano_plot)
```

## TPM calculation

We don't have the TPM values (we actually have them, but for the unstranded values). First, we need the **GENE LENGTH** for that, which we don't have. We can try to get this info from Ensembl.

```{r}
# Step 1: Connect to Ensembl
ensembl <- useMart("ensembl", dataset = "hsapiens_gene_ensembl")

# Step 2: Get all the gene names from merged_counts
gene_symbols <- rownames(merged_counts)

# Step 3: Retrieve gene lengths from Ensembl using biomaRt
# We want to retrieve 'hgnc_symbol' and 'transcript_length'
gene_lengths_df <- getBM(
  attributes = c("hgnc_symbol", "transcript_length", "transcript_is_canonical"),
  filters = "hgnc_symbol",
  values = gene_symbols,
  mart = ensembl
)

gene_lengths_df <- gene_lengths_df |> 
  dplyr::filter(!is.na(transcript_is_canonical))

# Convert to a named vector
gene_lengths <- setNames(gene_lengths_df$transcript_length, gene_lengths_df$hgnc_symbol)

# Check the resulting gene lengths
print(gene_lengths)
```

Now we can **normalize the raw counts to TPM**. We can easily do that manually in four steps:

1.  Calculate RPK (Reads Per Kilobase): RPK = counts / gene length in kilobases. This steps normalizes the counts for the gene length

2.  Calculate scaling factors: Sum all RPK values per sample

3.  Calculate corrector factor: Divide the scaling factor by 1 million (the result value is called corrector count)

4.  Calculate TPM: Normalize each RPK using the corrector factor. This normalizes for sequencing depth.

```{r}
# Step 1: Identify common gene names between counts data and gene lengths
common_genes <- intersect(rownames(merged_counts), names(gene_lengths))

# Step 2: Subset merged_counts to keep rows with genes that are in common_genes
counts_subset <- merged_counts[common_genes, ]

# Step 3: Subset gene_lengths to keep only genes that are in common_genes
gene_lengths_subset <- gene_lengths[common_genes]

# Step 4: Convert counts data frame to a matrix, as required by 'tpm'
counts_subset_matrix <- as.matrix(counts_subset)

# Step 5: Ensure gene_lengths are in numeric vector format
gene_lengths_vector <- as.numeric(gene_lengths_subset)

# Step 6: Calculate RPK
# Normalize counts by gene length (in kilobases)
rpk <- counts_subset_matrix / (gene_lengths_vector / 1000)

# Step 7: Calculate per-sample scaling factor
total_rpk_per_sample <- colSums(rpk)

# Step 8: Calculate the corrector counts by dividing total RPK by 1 million
corrector_counts <- total_rpk_per_sample / 1e6

# Step 9: Calculate TPM by dividing RPK by corrector counts for each sample
tpm_matrix <- t(t(rpk) / corrector_counts)

# Step 10: Convert TPM matrix back to a data frame
tpm_counts <- as.data.frame(tpm_matrix)

# Step 11: Log Normalize the tpm counts file.
log_normalized_tpm <- log2(tpm_counts + 1)

# Save the TPM values to a file
write.table(tpm_counts, file = "tpm_counts.tsv", sep = "\t", quote = FALSE, row.names = TRUE, col.names = TRUE)

# Save the log-normalized TPM values to a file
write.table(log_normalized_tpm, file = "log_normalized_tpm.tsv", sep = "\t", quote = FALSE, row.names = TRUE, col.names = TRUE)
```

Back to stratifying patients on the expression of the significantly differentially expressed genes between responders and non-responders.

```{r}
# Since the significant genes were found based on the raw counts, we need first to check if they are present in the tpm dataframe - we lose some genes here
common_significant_genes <- intersect(significant_gene_names, rownames(log_normalized_tpm))

# We will now implement a trick to check all individual significant genes. We will loop through all genes and store the results in a matrix.

# Create an empty matrix to store the p-values and significance for each gene
results_matrix <- matrix(nrow = length(common_significant_genes), ncol = 2)
rownames(results_matrix) <- common_significant_genes
colnames(results_matrix) <- c("p_value", "is_significant")

# Loop through each gene in common_significant_genes
for (gene in common_significant_genes) {
  # Extract the gene expression values from log_normalized_tpm
  gene_values <- as.matrix(log_normalized_tpm)[rownames(log_normalized_tpm) == gene, ]
  
  # Calculate biomarker status based on median split for the current gene
  metadata$biomarker_status <- gene_values > median(gene_values, na.rm = TRUE)

  # Perform survival analysis using the Kaplan-Meier and log-rank test
  sd <- survdiff(Surv(Survival_Time, Vital_Status) ~ biomarker_status, data = metadata)
  
  # Extract p-value from the survdiff result
  p_value <- 1 - pchisq(sd$chisq, length(sd$n) - 1)

  # Store p-value and significance in the results matrix
  results_matrix[gene, "p_value"] <- p_value
  results_matrix[gene, "is_significant"] <- p_value < 0.05
}

# Convert results_matrix to a data frame for easier viewing
results_df <- as.data.frame(results_matrix)
results_df$p_value <- as.numeric(results_df$p_value)
results_df$is_significant <- as.logical(results_df$is_significant)


# Apply Benjamini-Hochberg correction for multiple testing to the p-values
results_df$adjusted_p_value <- p.adjust(results_df$p_value, method = "BH")

# Add a new column to indicate significance after multiple testing correction
results_df$is_significant_corrected <- results_df$adjusted_p_value < 0.05

# Print the results data frame
print(results_df)

# After that you can create a Kaplan-Meier plot for the genes (not displayed here)
```

## ssGSEA

We found some genes that can point out a statistical difference in the survival of the two groups (higher or lower expression of a gene). But genes rarely work individually in nature, so let's take a multivariate approach, that is, define a group of genes. We will start by selecting the e.g. 15 most significantly up regulated genes in responders, calculate the sample wise gene set enrichment and split again the patients into two groups.

```{r}
# Get only the 15 most significantly up regulated genes
res2 <- res[res$padj < 0.05 & res$log2FoldChange > 0,]
gene_set <- list(responder_set = rownames(res2[order(res2$padj),])[1:15])

# Perform the sample wise gene set enrichment
param <- ssgseaParam(as.matrix(log_normalized_tpm), gene_set)
enrich <- gsva(param)

# Perform the log-rank and produce the plot
metadata$biomarker_status <- enrich[1,] > median(enrich[1,])
sd <- survdiff(Surv(Survival_Time, Vital_Status) ~ biomarker_status, data = metadata) 
sd 

# Save the p-value
p_value <- 1 - pchisq(sd$chisq, length(sd$n) - 1)

km <- survfit(Surv(Survival_Time, Vital_Status) ~ biomarker_status, data = metadata) 
plot(km, xlim = c(0, 1200), xlab = "Time in Days", ylab = "Survival Probability",main = "Kaplan-Meier Plot")
text(x = 800, y = 0.2, labels = paste("p-value =", round(p_value, 4)), col = "red", cex = 1.2)
```

```{r}
# ALTERNATIVE APPROACH
# Get a subset of the results of the DESeq genes that can stratify efficiently the patients
significant_genes_df <- results_df %>% filter(is_significant == TRUE)

# And now follow the same approach as the code block before
# Ensure the significant_genes_df has rownames, which are the gene names
significant_gene_names <- rownames(significant_genes_df)

# Extract the significant genes from 'res' (the original DESeq2 results)
significant_genes_with_logfc <- res[significant_gene_names, ]

# Keep only upregulated genes (log2FoldChange > 0) and order by adjusted p-value
res3 <- significant_genes_with_logfc %>%
  filter(log2FoldChange > 0) %>%   # Filter for upregulated genes
  arrange(padj)                    # Sort by adjusted p-value

# Select the top 15 most significant genes
gene_set <- list(responder_set = rownames(res3)[1:15])

# Perform the sample wise gene set enrichment
param <- ssgseaParam(as.matrix(log_normalized_tpm), gene_set)
enrich <- gsva(param)

# Perform the log rank and produce the plot
metadata$biomarker_status <- enrich[1,] > median(enrich[1,])
sd <- survdiff(Surv(Survival_Time, Vital_Status) ~ biomarker_status, data = metadata) 
sd 

# Save the p-value
p_value <- 1 - pchisq(sd$chisq, length(sd$n) - 1)

km <- survfit(Surv(Survival_Time, Vital_Status) ~ biomarker_status, data = metadata) 
plot(km, xlim = c(0, 1200), xlab = "Time in Days", ylab = "Survival Probability",main = "Kaplan-Meier Plot")
text(x = 800, y = 0.2, labels = paste("p-value =", round(p_value, 4)), col = "red", cex = 1.2)
```
